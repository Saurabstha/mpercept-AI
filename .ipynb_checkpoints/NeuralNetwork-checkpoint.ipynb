{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-1,-1,101)\n",
    "y = 2*x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1,input_dim=1,activation='linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('sgd', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 101 samples\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 0s 2ms/sample - loss: 0.3614\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 0.2607\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.1881\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 0.1357\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0979\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 0.0706\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0509\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0367\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0265\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0191\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0138\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 0.0100\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0072\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0052\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 0.0037\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0027\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 0.0019\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0014\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 0.0010\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 7.2988e-04\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 5.2653e-04\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 3.7984e-04\n",
      "Epoch 23/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 2.7401e-04\n",
      "Epoch 24/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 1.9766e-04\n",
      "Epoch 25/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 1.4259e-04\n",
      "Epoch 26/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 1.0287e-04\n",
      "Epoch 27/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 7.4208e-05\n",
      "Epoch 28/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 5.3533e-05\n",
      "Epoch 29/100\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 3.8618e-05\n",
      "Epoch 30/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 2.7859e-05\n",
      "Epoch 31/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 2.0097e-05\n",
      "Epoch 32/100\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 1.4498e-05\n",
      "Epoch 33/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 1.0458e-05\n",
      "Epoch 34/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 7.5450e-06\n",
      "Epoch 35/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 5.4429e-06\n",
      "Epoch 36/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 3.9264e-06\n",
      "Epoch 37/100\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 2.8326e-06\n",
      "Epoch 38/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 2.0436e-06\n",
      "Epoch 39/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 1.4742e-06\n",
      "Epoch 40/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 1.0635e-06\n",
      "Epoch 41/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 7.6719e-07\n",
      "Epoch 42/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 5.5360e-07\n",
      "Epoch 43/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 3.9951e-07\n",
      "Epoch 44/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 2.8825e-07\n",
      "Epoch 45/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 2.0790e-07\n",
      "Epoch 46/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 1.4987e-07\n",
      "Epoch 47/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 1.0810e-07\n",
      "Epoch 48/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 7.7996e-08\n",
      "Epoch 49/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 5.6271e-08\n",
      "Epoch 50/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 4.0597e-08\n",
      "Epoch 51/100\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 2.9277e-08\n",
      "Epoch 52/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 2.1097e-08\n",
      "Epoch 53/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 1.5222e-08\n",
      "Epoch 54/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 1.0983e-08\n",
      "Epoch 55/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 7.9145e-09\n",
      "Epoch 56/100\n",
      "101/101 [==============================] - 0s 158us/sample - loss: 5.7113e-09\n",
      "Epoch 57/100\n",
      "101/101 [==============================] - 0s 138us/sample - loss: 4.1176e-09\n",
      "Epoch 58/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 2.9701e-09\n",
      "Epoch 59/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 2.1479e-09\n",
      "Epoch 60/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 1.5565e-09\n",
      "Epoch 61/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 1.1226e-09\n",
      "Epoch 62/100\n",
      "101/101 [==============================] - 0s 119us/sample - loss: 8.0650e-10\n",
      "Epoch 63/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 5.8180e-10\n",
      "Epoch 64/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 4.1783e-10\n",
      "Epoch 65/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 3.0503e-10\n",
      "Epoch 66/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 2.1722e-10\n",
      "Epoch 67/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 1.5867e-10\n",
      "Epoch 68/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 1.1440e-10\n",
      "Epoch 69/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 8.0894e-11\n",
      "Epoch 70/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 5.9074e-11\n",
      "Epoch 71/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 4.4297e-11\n",
      "Epoch 72/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 3.2519e-11\n",
      "Epoch 73/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 2.2560e-11\n",
      "Epoch 74/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 1.5379e-11\n",
      "Epoch 75/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 1.0031e-11\n",
      "Epoch 76/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 7.2833e-12\n",
      "Epoch 77/100\n",
      "101/101 [==============================] - 0s 118us/sample - loss: 6.0535e-12\n",
      "Epoch 78/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 4.9375e-12\n",
      "Epoch 79/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 4.4221e-12\n",
      "Epoch 80/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 3.7866e-12\n",
      "Epoch 81/100\n",
      "101/101 [==============================] - 0s 148us/sample - loss: 3.4766e-12\n",
      "Epoch 82/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 2.9159e-12\n",
      "Epoch 83/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 2.6448e-12\n",
      "Epoch 84/100\n",
      "101/101 [==============================] - 0s 69us/sample - loss: 2.1589e-12\n",
      "Epoch 85/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 1.9266e-12\n",
      "Epoch 86/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 1.5156e-12\n",
      "Epoch 87/100\n",
      "101/101 [==============================] - ETA: 0s - loss: 1.4211e-1 - 0s 119us/sample - loss: 1.3222e-12\n",
      "Epoch 88/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 9.8604e-13\n",
      "Epoch 89/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 8.3141e-13\n",
      "Epoch 90/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 5.7012e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 5.1159e-13\n",
      "Epoch 92/100\n",
      "101/101 [==============================] - 0s 128us/sample - loss: 5.1159e-13\n",
      "Epoch 93/100\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 5.1159e-13\n",
      "Epoch 94/100\n",
      "101/101 [==============================] - 0s 79us/sample - loss: 5.1159e-13\n",
      "Epoch 95/100\n",
      "101/101 [==============================] - 0s 109us/sample - loss: 5.1159e-13\n",
      "Epoch 96/100\n",
      "101/101 [==============================] - 0s 69us/sample - loss: 5.1159e-13\n",
      "Epoch 97/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 5.1159e-13\n",
      "Epoch 98/100\n",
      "101/101 [==============================] - 0s 99us/sample - loss: 5.1159e-13\n",
      "Epoch 99/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 5.1159e-13\n",
      "Epoch 100/100\n",
      "101/101 [==============================] - 0s 89us/sample - loss: 5.1159e-13\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x,y,nb_epoch=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1 [========================================================================================================================] - 0s 11ms/sample - loss: 0.2489\n",
      "0.24888591468334198\n"
     ]
    }
   ],
   "source": [
    "test_x = np.array([1000,100,1200,1900])/1900\n",
    "test_y = 2*test_x\n",
    "# test_y = keras.utils.to_cateorical(test_y, num_classes = 2)\n",
    "\n",
    "test = model.evaluate(test_x,test_y) #gives loss and accuracy\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168.2899 ]\n",
      " [170.01001]\n",
      " [171.73012]\n",
      " [173.45021]\n",
      " [175.17032]\n",
      " [176.89041]\n",
      " [178.61052]\n",
      " [180.3306 ]\n",
      " [182.0507 ]\n",
      " [183.77081]\n",
      " [185.4909 ]\n",
      " [187.21101]\n",
      " [188.9311 ]\n",
      " [190.65121]\n",
      " [192.3713 ]\n",
      " [194.09142]\n",
      " [195.81151]\n",
      " [197.53162]\n",
      " [199.25171]\n",
      " [200.9718 ]\n",
      " [202.69191]\n",
      " [204.412  ]\n",
      " [206.13211]\n",
      " [207.8522 ]\n",
      " [209.57231]\n",
      " [211.2924 ]\n",
      " [213.01251]\n",
      " [214.73262]\n",
      " [216.45271]\n",
      " [218.17282]\n",
      " [219.89291]\n",
      " [221.61302]\n",
      " [223.33311]\n",
      " [225.05322]\n",
      " [226.77332]\n",
      " [228.49342]\n",
      " [230.21353]\n",
      " [231.93362]\n",
      " [233.6537 ]\n",
      " [235.37381]\n",
      " [237.0939 ]\n",
      " [238.81401]\n",
      " [240.5341 ]\n",
      " [242.25421]\n",
      " [243.9743 ]\n",
      " [245.69441]\n",
      " [247.4145 ]\n",
      " [249.13461]\n",
      " [250.8547 ]\n",
      " [252.57481]\n",
      " [254.29492]\n",
      " [256.015  ]\n",
      " [257.7351 ]\n",
      " [259.45523]\n",
      " [261.17532]\n",
      " [262.89542]\n",
      " [264.6155 ]\n",
      " [266.33563]\n",
      " [268.05573]\n",
      " [269.77582]\n",
      " [271.49594]\n",
      " [273.21603]\n",
      " [274.9361 ]\n",
      " [276.65622]\n",
      " [278.3763 ]\n",
      " [280.0964 ]\n",
      " [281.8165 ]\n",
      " [283.53662]\n",
      " [285.2567 ]\n",
      " [286.9768 ]\n",
      " [288.6969 ]\n",
      " [290.41702]\n",
      " [292.13712]\n",
      " [293.8572 ]\n",
      " [295.57733]\n",
      " [297.29742]\n",
      " [299.01752]\n",
      " [300.7376 ]\n",
      " [302.45773]\n",
      " [304.17783]\n",
      " [305.89792]\n",
      " [307.618  ]\n",
      " [309.33813]\n",
      " [311.05823]\n",
      " [312.77832]\n",
      " [314.49844]\n",
      " [316.21854]\n",
      " [317.9386 ]\n",
      " [319.65872]\n",
      " [321.3788 ]\n",
      " [323.0989 ]\n",
      " [324.819  ]\n",
      " [326.53912]\n",
      " [328.25922]\n",
      " [329.9793 ]\n",
      " [331.6994 ]\n",
      " [333.41953]\n",
      " [335.13962]\n",
      " [336.8597 ]\n",
      " [338.57983]]\n",
      "\r",
      "100/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 50us/sample - loss: 3154.7328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2347.92888671875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_input = np.linspace(100,201,100)\n",
    "predictions = model.predict(predict_input)\n",
    "print(predictions)\n",
    "model.evaluate(predict_input,2*predict_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving\n",
    "# serialize model to json\n",
    "model_json = model.to_json()\n",
    "\n",
    "# model config as json\n",
    "with open(\"day1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "#serialize weight to HDF5\n",
    "model.save_weights(\"day1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "with open('day1.json','r') as f:\n",
    "    model_loaded = model_from_json(f.read())\n",
    "    \n",
    "# load weights into new model\n",
    "model_loaded.load_weights('day1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9845703499 sudhan kadel\n",
    "# sgd ra momentum optimizer.. momentum bala ma purano balako wt ni herxa\n",
    "# momentum parameter\n",
    "# adam optimizer\n",
    "# each epoc ma wt update garda dher time lagxa,, if 32 batch size(if 3200 ota example xa vane),, pahila 100(batch size = total example/harek batch ma hune example) ota example train garaune ani wt update garaune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
