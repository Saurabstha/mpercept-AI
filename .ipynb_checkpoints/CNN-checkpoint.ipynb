{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suraj shrestha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-f+1\n",
    "# f is filter matrix ko size\n",
    "# n vanya original ko size\n",
    "# padding garexi loss hudaina\n",
    "# pooling garexi sizze ghatxa( matrix ko)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(2,2),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(2,2),activation='relu'))\n",
    "# yo 2 ta line le features extract garxa,, kernel size 2,2 ko 32 ota filters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))  #input layer with 128 neuron\n",
    "model.add(Dense(64,activation='relu'))  #hidden layer with 64 neuron\n",
    "model.add(Dense(10,activation='softmax')) #output layer with 10 neuron\n",
    "# dense fully connected layer\n",
    "# softmaX LE probablity nikalxa 10 ota madhe jasko prob high hunxa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 27, 27, 32)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 64)        8256      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 5,555,242\n",
      "Trainable params: 5,555,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "img_gen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37940 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img_gen = img_gen.flow_from_directory('mnist_data/trainingSet/', \n",
    "                                            target_size=(28,28),\n",
    "                                            batch_size=16,\n",
    "                                            class_mode='categorical',\n",
    "                                            color_mode='grayscale')\n",
    "\n",
    "# 16 batch ma one epoch ani ek xoti ma 37940/16 ota image pathaune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4060 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validate_img_gen = img_gen.flow_from_directory('mnist_data/validatingSet/', \n",
    "                                            target_size=(28,28),\n",
    "                                            batch_size=16,\n",
    "                                            class_mode='categorical',\n",
    "                                            color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s 187ms/step - loss: 0.3417 - accuracy: 0.8994 - val_loss: 0.2668 - val_accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "result = model.fit_generator(train_img_gen,validation_data=validate_img_gen,validation_steps=12,epochs=1,steps_per_epoch=100)\n",
    "# ek epoch ma 100 ota img matra train hune ,, baki image xutxa hai guys\n",
    "# collab ma free gpu dinxa hai guys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_model_stepsPerEpoch100.h5')\n",
    "# architecture ra weight same ma save hunxa hai guys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# a = cv2.imread('mnist_data\\testSet\\img_2.jpg',0)\n",
    "# a= cv2.resize(a,(28,28))\n",
    "# print(a.shape)\n",
    "# a = np.expand_dims(a, axis=0)\n",
    "# test_img = np.expand_dims(a,axis=0)\n",
    "# test_img = test_img.transpose((1,2,3,0))\n",
    "# print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of a : (28, 28)\n",
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "a = cv2.imread('mnist_data/testSet/img_2.jpg',0)\n",
    "plt.imshow(a)\n",
    "plt.show()\n",
    "a = cv2.resize(a,(28,28))\n",
    "print(\"shape of a :\",a.shape)\n",
    "a =np.expand_dims(a,axis=0)\n",
    "# 28,28,1 1 for grayscale\n",
    "test_img = np.expand_dims(a,axis=0)\n",
    "# 1,1,28,28 xai transpose garexi 1,28,28,1\n",
    "test_img = test_img.transpose((1,2,3,0))/255\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.predict_classes(test_img)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "# look yolo\n",
    "# train mnist model with higher accuracy with diff optimizers and loss fn layer\n",
    "# look after transfer learninf\n",
    "# install pycharm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
